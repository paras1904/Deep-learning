# -*- coding: utf-8 -*-
"""Voice Cloning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JfE5KIlh1fzCgqTrJKwhF9tR9_pTcyEN
"""

# Commented out IPython magic to ensure Python compatibility.
# Cloning the repository
!git clone https://github.com/misbah4064/Real-Time-Voice-Cloning.git

# Changing the current directory to the repository's directory
# %cd Real-Time-Voice-Cloning/

# Installing the dependencies
!pip install -q -r requirements.txt
!pip install pydub
!apt-get install -qq libportaudio2

# Downloading pretrained data and unzipping it
!gdown https://drive.google.com/uc?id=1n1sPXvT34yXFLT47QZA6FIRGrwMeSsZc
!unzip pretrained.zip

# Initializing all the encoder libraries
from IPython.display import Audio
from IPython.utils import io
from synthesizer.inference import Synthesizer
from encoder import inference as encoder
from vocoder import inference as vocoder
from pathlib import Path
import numpy as np
import librosa

in_fpath = 'trump10.wav'

encoder_weights = Path("encoder/saved_models/pretrained.pt")
vocoder_weights = Path("vocoder/saved_models/pretrained/pretrained.pt")
syn_dir = Path("synthesizer/saved_models/logs-pretrained/taco_pretrained")
encoder.load_model(encoder_weights)
synthesizer = Synthesizer(syn_dir)
vocoder.load_model(vocoder_weights)
reprocessed_wav = encoder.preprocess_wav(in_fpath)
original_wav, sampling_rate = librosa.load(in_fpath)
preprocessed_wav = encoder.preprocess_wav(original_wav, sampling_rate)
embed = encoder.embed_utterance(preprocessed_wav)

def audtext(text,embed):
  with io.capture_output() as captured:
    specs = synthesizer.synthesize_spectrograms([text], [embed])
  generated_wav = vocoder.infer_waveform(specs[0])
  generated_wav = np.pad(generated_wav, (0, synthesizer.sample_rate), mode="constant")
  display(Audio(generated_wav, rate=synthesizer.sample_rate))

while(True):
  n = input()
  if n=='Quit':
    break
  else:
    audtext(n,embed)

